{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At first I create a char level prediction to compare to other models and then I will go for word level to get more meaningful result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see LSTM makes way more meaningful char level predictions compare to simple rnn and embedding. The word level predictions with LSTM will be available soon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f\"Device is: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¹', '‒', '—', '―', '‘', '’', '“', '”', '•', '™', '♠', '♦', '\\ufeff']\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, seq_length):\n",
    "        chars = sorted(list(set(text)))\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "        self.vocab_size = len(chars)\n",
    "        self.seq_length = seq_length\n",
    "        self.data = [self.char_to_idx[char] for char in text]\n",
    "\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        for i in range(0, len(self.data) - seq_length):\n",
    "            self.inputs.append(self.data[i:i + seq_length])\n",
    "            self.targets.append(self.data[i + 1:i + seq_length + 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "\n",
    "# Load the text data\n",
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "seq_length = 50\n",
    "dataset = TextDataset(text, seq_length)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, num_layers=6)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # LSTM has two hidden states, hidden state and cell state\n",
    "        return (torch.zeros(6, batch_size, self.hidden_size),\n",
    "                torch.zeros(6, batch_size, self.hidden_size))\n",
    "\n",
    "# Model parameters\n",
    "input_size = dataset.vocab_size\n",
    "hidden_size = 128\n",
    "output_size = dataset.vocab_size\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example of how to use init_hidden\n",
    "batch_size = 32  # Example batch size\n",
    "hidden = model.init_hidden(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTM(\n",
       "  (embedding): Embedding(96, 128)\n",
       "  (lstm): LSTM(128, 128, num_layers=6, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=96, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5201\n",
      "Epoch [2/10], Loss: 1.1072\n",
      "Epoch [3/10], Loss: 0.9887\n",
      "Epoch [4/10], Loss: 0.9178\n",
      "Epoch [5/10], Loss: 0.8719\n",
      "Epoch [6/10], Loss: 0.8398\n",
      "Epoch [7/10], Loss: 0.8162\n",
      "Epoch [8/10], Loss: 0.7982\n",
      "Epoch [9/10], Loss: 0.7838\n",
      "Epoch [10/10], Loss: 0.7719\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Initialize hidden state for the current batch\n",
    "        hidden = model.init_hidden(x_batch.size(0))\n",
    "        hidden = (hidden[0].to(device), hidden[1].to(device))\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, hidden = model(x_batch, hidden)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, output_size), y_batch.view(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "e  tis neiore  Tocelyod will nive me treatly se tene cg aoom the storp toews of the snsisible.tytus t wauld nae tou w hm sore tou wiuld ne teeutiful  r ess, Ieent we  aheet fesus  ahat Ihe  aay becenthae toristians aeu man sith tils wontinence ooe ouh  an teleueof ter sisitars, The leople wad niavnedt saapehinking tefore the sord  tnd tt eng  aIee e  ohe  elves   seclared the Woy.\n",
      "\n",
      "\"Whe Wrincess O the sonerable torden te ees and tiy tn the eaek   u aust beow  and t way factiredoe sremucei tn thehee  iiraauld bot boinge teaces oilh tt ipter tly  o oy tn o  an 't it \" \n",
      "\"In ior thet \"ah cre nn th\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "# for one layer of LSTM\n",
    "# Epoch [1/10], Loss: 1.4503\n",
    "# Epoch [2/10], Loss: 1.2842\n",
    "# Epoch [3/10], Loss: 1.2499\n",
    "# Epoch [4/10], Loss: 1.2320\n",
    "# Epoch [5/10], Loss: 1.2211\n",
    "# Epoch [6/10], Loss: 1.2134\n",
    "# Epoch [7/10], Loss: 1.2080\n",
    "# Epoch [8/10], Loss: 1.2035\n",
    "# Epoch [9/10], Loss: 1.2004\n",
    "# Epoch [10/10], Loss: 1.1974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 50, 96])\n",
      "torch.Size([12, 50])\n",
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "    ehe Wirl tnguired.\n",
      "\n",
      "\"N will sead you eo bt, Iotnd tove on tuch a  efful sistance.aoom the srave.he wrlh oraw aeoodes she  wrt the buggy ao ether ae thken uff trom his potours anong thet meaple  whrns ng  _mmgust 10, h754..\n",
      "\n",
      "                 * *   f ol th mfhers. tn yoe wnew  it was aure tlestid n ae n ixen mere anazed toet torothy at ahe e ltreteice \n",
      "\n",
      "\"T -I m 'mraid,ye s -ae's aon ing tway!\" c\n",
      "ome  Ta boul ws areatly beawn aut oster God, aor u  ns d  Oomwn wuesday  February 10 at was mrt ip tndther  a could naarce telp muew  ng thrrs  ah th th the crnversion of Ghe mrwr mnsians, \n",
      "W have nu\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "\n",
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "print(predicted_indices.shape)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "# two layer, two times of training loop\n",
    "# Epoch [1/10], Loss: 1.3919\n",
    "# Epoch [2/10], Loss: 1.1777\n",
    "# Epoch [3/10], Loss: 1.1169\n",
    "# Epoch [4/10], Loss: 1.0814\n",
    "# Epoch [5/10], Loss: 1.0575\n",
    "# Epoch [6/10], Loss: 1.0408\n",
    "# Epoch [7/10], Loss: 1.0285\n",
    "# Epoch [8/10], Loss: 1.0189\n",
    "# Epoch [9/10], Loss: 1.0113\n",
    "# Epoch [10/10], Loss: 1.0052\n",
    "# Epoch [1/10], Loss: 1.0002\n",
    "# Epoch [2/10], Loss: 0.9959\n",
    "# Epoch [3/10], Loss: 0.9922\n",
    "# Epoch [4/10], Loss: 0.9891\n",
    "# Epoch [5/10], Loss: 0.9865\n",
    "# Epoch [6/10], Loss: 0.9844\n",
    "# Epoch [7/10], Loss: 0.9822\n",
    "# Epoch [8/10], Loss: 0.9804\n",
    "# Epoch [9/10], Loss: 0.9785\n",
    "# Epoch [10/10], Loss: 0.9768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 50, 96])\n",
      "torch.Size([12, 50])\n",
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "e  thell I be one of the children \n",
      "\n",
      "Sunday 24. In   te tome anain wfter all\n",
      "the dood ohmes,I ve had tect be ducked wefore Ghe  wam hecome pood corizen thet tsual to reairedfrom the warld, yea aven fro  tre  thtl he pccepteble to the geous readers \n",
      "“Aeteurs  ao an ungulrded hhrds ―You will not  by doe aven foe wressed Serf- Ihe  hhall I be gossessedte trad to weet aour w'm sure.\"\n",
      "\n",
      "\"Sou day be tight trtnthe buggy edgewise, wh it would toke up the weion oawedould I stng ” And calling on these tho w  deof atcrined townellsed upward aor alpay  and tet i mao am nhe caast cf all the wtrvants,Ihould b\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "\n",
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "print(predicted_indices.shape)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "\n",
    "# 5 layers of LSTM\n",
    "# Epoch [1/10], Loss: 1.4840\n",
    "# Epoch [2/10], Loss: 1.1002\n",
    "# Epoch [3/10], Loss: 0.9972\n",
    "# Epoch [4/10], Loss: 0.9340\n",
    "# Epoch [5/10], Loss: 0.8914\n",
    "# Epoch [6/10], Loss: 0.8604\n",
    "# Epoch [7/10], Loss: 0.8377\n",
    "# Epoch [8/10], Loss: 0.8198\n",
    "# Epoch [9/10], Loss: 0.8055\n",
    "# Epoch [10/10], Loss: 0.7936\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 50, 96])\n",
      "torch.Size([12, 50])\n",
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "nnd  aotshall bat thembrod of tho wont._ He said ue oicedtn  Th my love,  hes is aight, pnd may you  I mow gach dis these ovcellent anes of the bnrth e  the Wizard. \"arnestly. \"Oet us nll me d mappy tht wid not wrcore  an it i was ahere tod hiuld navs sonntrnance  and hf thet Ieace which passeth alld  ahrned antbhe airection of the Cinld. and the bhthe witonished oap-horse eouling wner mnd aver  ahtnough tor aim to boaw mhe buggy aasily acter aim aee  wf the snfluence  of the sin.of righteousneshtf y anil tondrnually_. She wad nothrwer to pray n dtoom his focket and wook hrom tt woveral otarp \n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "\n",
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "print(predicted_indices.shape)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "\n",
    "# 6 layers of LSTM\n",
    "# Epoch [1/10], Loss: 1.5201\n",
    "# Epoch [2/10], Loss: 1.1072\n",
    "# Epoch [3/10], Loss: 0.9887\n",
    "# Epoch [4/10], Loss: 0.9178\n",
    "# Epoch [5/10], Loss: 0.8719\n",
    "# Epoch [6/10], Loss: 0.8398\n",
    "# Epoch [7/10], Loss: 0.8162\n",
    "# Epoch [8/10], Loss: 0.7982\n",
    "# Epoch [9/10], Loss: 0.7838\n",
    "# Epoch [10/10], Loss: 0.7719"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
