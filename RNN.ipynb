{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¹', '‒', '—', '―', '‘', '’', '“', '”', '•', '™', '♠', '♦', '\\ufeff']\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '?', 28: 'A', 29: 'B', 30: 'C', 31: 'D', 32: 'E', 33: 'F', 34: 'G', 35: 'H', 36: 'I', 37: 'J', 38: 'K', 39: 'L', 40: 'M', 41: 'N', 42: 'O', 43: 'P', 44: 'Q', 45: 'R', 46: 'S', 47: 'T', 48: 'U', 49: 'V', 50: 'W', 51: 'X', 52: 'Y', 53: 'Z', 54: '[', 55: ']', 56: '_', 57: 'a', 58: 'b', 59: 'c', 60: 'd', 61: 'e', 62: 'f', 63: 'g', 64: 'h', 65: 'i', 66: 'j', 67: 'k', 68: 'l', 69: 'm', 70: 'n', 71: 'o', 72: 'p', 73: 'q', 74: 'r', 75: 's', 76: 't', 77: 'u', 78: 'v', 79: 'w', 80: 'x', 81: 'y', 82: 'z', 83: '¹', 84: '‒', 85: '—', 86: '―', 87: '‘', 88: '’', 89: '“', 90: '”', 91: '•', 92: '™', 93: '♠', 94: '♦', 95: '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [char_to_idx[char] for char in text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(data) == len(text):\n",
    "#     print(f\"True! Length is {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = []\n",
    "# targets = []\n",
    "# seq_length = 100\n",
    "\n",
    "# for i in range(0, len(data) -seq_length):\n",
    "#     inputs.append(data[i:i+seq_length])\n",
    "#     targets.append(data[i+1:i+seq_length+1])\n",
    "\n",
    "# inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "# targets = torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputs.size())\n",
    "# print(targets.size())\n",
    "# inputs.to(device)\n",
    "# targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, seq_length):\n",
    "        chars = sorted(list(set(text)))\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "        self.vocab_size = len(chars)\n",
    "        self.seq_length = seq_length\n",
    "        self.data = [self.char_to_idx[char] for char in text]\n",
    "\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        for i in range(0, len(self.data) - seq_length):\n",
    "            self.inputs.append(self.data[i:i + seq_length])\n",
    "            self.targets.append(self.data[i + 1:i + seq_length + 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "\n",
    "# Load the text data\n",
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "seq_length = 50\n",
    "dataset = TextDataset(text, seq_length)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n",
    "\n",
    "# Model parameters\n",
    "input_size = dataset.vocab_size\n",
    "hidden_size = 128\n",
    "output_size = dataset.vocab_size\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNV2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNNV2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True, num_layers=5)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(5, batch_size, self.hidden_size)\n",
    "\n",
    "# Model parameters\n",
    "input_size = dataset.vocab_size\n",
    "hidden_size = 192\n",
    "output_size = dataset.vocab_size\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleRNNV2(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNNV2(\n",
       "  (embedding): Embedding(96, 192)\n",
       "  (rnn): RNN(192, 192, num_layers=5, batch_first=True)\n",
       "  (fc): Linear(in_features=192, out_features=96, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2739\n",
      "Epoch [2/10], Loss: 1.1504\n",
      "Epoch [3/10], Loss: 1.1516\n",
      "Epoch [4/10], Loss: 1.1677\n",
      "Epoch [5/10], Loss: 1.1936\n",
      "Epoch [6/10], Loss: 1.2190\n",
      "Epoch [7/10], Loss: 1.2252\n",
      "Epoch [8/10], Loss: 1.2317\n",
      "Epoch [9/10], Loss: 1.2414\n",
      "Epoch [10/10], Loss: 1.2528\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Initialize hidden state for the current batch\n",
    "        hidden = model.init_hidden(x_batch.size(0)).to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, hidden = model(x_batch, hidden)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, output_size), y_batch.view(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[1,1].size()\n",
    "output[1,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 50, 96])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "  hartoat teen se hhoulod tes hlltee \"ra ioe shoatr htthetkful for the snweeakable aercies af God wo  ahin ver sae wad bhe giast oonport tf orrce  aoer anue in the shmsetion w am sheught to be an tu lt              aesipieg faarivr   of tr. _rEINERD. tizard \n",
      "\"Wust tot  ay dear  tha e ws no  t single ss,teesseyourwrd teep mour and toacteahat tt t l   an ie  poars on rease   ae  sood tster tanding  teice. \n",
      "\n",
      "\"Iu rs,\" cxclaimed torothy, \"Ire yhe e wo  ainknn ng  ahe wecame oyend  ahin tne of the siue i \n",
      "\n",
      "\"Iow song till bou te tith ts   ae asked.\n",
      "\n",
      "\" Ihv aew spnan ir itt ms thaepeng tnd sasing  \n",
      " ueaovi ent of thme  and the sieceietc of tir sovsimetn ahe samelt tind of t bizard,wh bive   replied t  ng iod_hrr t tonryr’s soowd  Bhe e  aha e pre todtotde ahe walley onsily anough   snswered the gantn tore aapnently so te afserved  \n",
      "\"Shme oime thn hkle  anlo,\" \n",
      "\"Io,\" answered the gizard.\n",
      "\"Ierple a  dedhod fo beke mny shing t waite af teiefit oo tr weve tt.ilain,\"\n",
      "\n",
      "\"Tos, wf eed   semurned the gite sitten wes bhiad to someutttor shoee  and thet itnd the soegronts aes wo red my ide tt  T herssoildet srt ty seaires tn traytice as t cauld  buess d tut of tuoep, ahe wecan to bearovch oe eelf, aor tne she ghoughts wh ards te, Ant thisgs ahell Ierktou wi d shmeng  of traat doy   Thi paemy porlred n  d  and the sitht thell wtene of the goy  , W  ethtked tane tn o the eoof  Iot tt ie tolled with t \n",
      "a deaires tere sych dnlarged tnter tod, ahth a s  and the std birse aad been aefaeng te to so tiletnd trcces af tross sere aiing ooartered tn avery nhtor te seoatfast  ao t aaiat tt o the woof oiine\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "hetuieng teue  avpecteng tesigerence wpder tvery tt             * \n",
      "\n",
      " My dear friend_,\n",
      "\n",
      "I HHASG  ou m   said teb, who he tet aed andag hed the gorse  \n",
      " said tim. \n",
      "\"Ih, Io \" snswered the Wawhorse.\n",
      "\"I wa s not sake m y ooala. and tornd mo  ing set tive e ng tnd taegtron whce \"\n",
      "Sonday 13. Ill to terday he   ore ihesghtI wften tord mhet treyse terbledsad tane mt asrod  aath the wlight  of tes fonntrnan    \n",
      "Suturday  Mugust 4. I wave neen aar toveral d  \n",
      "he e ware aotmearrs,os the r herses  aucause the ssarn wnlo  Tut aheuld hs we tfhersise  aou  hve   and tanelre  tith the   \n",
      "e was a p to shesk oaf ae ter t hhould se aeadyng te setle. Io t aalh aeaeldnow tot the Live of God  Tow wach ase these whe i   ahs the foarch of tsngland_, ar. _M._ weght u ad tn  tor tvery mocelty of ty soul,was been aare ais novrey si k ng  ae thes time  ahice t ma,was  tlain,t thou_  bnd t wm su tor arom teing ahoco thell Ii it tou wo 't kat uhese wovtle ceils af teteygeroon t lays ahe fordest de solt  \n",
      "\"Iou wast beT                                        31.\n",
      "  Il olaat dansernitfer ime te t shifling soirit  T hod tonht a                  Aline toe mork  ootmore teve nover mholy sealatad teftor iven  Te hrswer e The  t lerdenltorneteought the  ah s lemrow arrl orrted toeallhaen, tecutiful tn eed tft ard y  audtath ahe saattff er d to e of tis feople wo solrythi  ahice t was a  troyer, ahat t mav aeen ahlkin s wy soul wn trrfect teace, ahice t l ttound te teneortable leue oheinteipo ahat Ihe Lord wauld bav  rd ftne oe ticerorr the saatt  \n",
      "\"Ihyr I ahw tGo,eo areat aaithfaor the woalare hf tebns and tewe t\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "                                            Yuston  tnl the wext may  ao tn tot th se a le to tesl tr her sarsage aoayLoyl aeeek oncoss in and slsotkee  srew uha  wam ot be mavd to tealiy seves and th\n",
      "as an tych tove  ahll tn  ofclock in the morning  d me wert to tie the snflrmity, Tvery hing sn toango ty pind  H welged the Lord so deve te tower to  oerr   aA_tl_ Thet is ws a lolutely seong wrr a uessed be God, I found my soul wesoeshed in trivat                                                 *er \n",
      "\n",
      "\"n se haoke ahe seice oane to tear th teb,hhiae was allo gxdurd tith a sonstant ptirit of traye oru frother_,\n",
      "\n",
      " ―A pN sn tre oontinuad tnd snwvge II―rd, ghougmnowest anl thesgs  bheu snowest ahetnd sove  ahch ancoion,ooom t ove. Oors thes momry  aou aonpla with taragraph 1.E.1.or e.E.1. \n",
      "A.E.7.l ,sare aenens of the suaintedt and most pactures  fe. bnd andess you aoo  tullina,and sureka  woye   a woot tt  Hord, give me tower tver mnshifling sdng  aIpnuit t., 1754..\n",
      "\n",
      "                         hnn  tnd sfdise    sorny seceivedtrom tne mf anythn temgrr ng and sherst ng tef n fiel  to so tis lo   and tooe tis iith a l ty seart  \n",
      "Thursday 2. I  nrd tyct bi hee Iho hauld nlo fiam a pegnd of trt           y r t soment ny torn.                  r ing ,  Ih  maa ought  that I mauld not shemty br rh r tn ihe shanm of the sarcerersias sesunsing o nains aor I cove to mai from ty sndians  ―A―― oave tver beth aou. and toit iot,to temember on the s r mt aaine tt wuly tan be firnd  I  the evening Ih cid 't snk th tome town tire  bh will   said torltia mou tooito moushean ty moylk  and tlter ardsm\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "  d tarld 's srotalh ty th t ra at an \n",
      "\n",
      "\"I m antoi  why the saowe  and tes toaige  d \n",
      "Th e hmes an w  ary t. Mrdng tnsattle tvrtyes toet tneallth tresreng tfr af the srwtare t sas ty elf tn thir I warRSEL. 1et ark 12.e I769. 1hen I wmake mt the soreirr ess ond at oceny.on n te sond tnl the siy  Ihe  m \n",
      "\"      ettenaredtirkswIn  tepeve  t unday  M hroscenle tath ng M mhet theugaeold   sorl be tath as anotr.atinitrnntain \n",
      "\n",
      "\n",
      "TWse ti cuey tavf aas an wart th teong tile te sittle trildrtrom te sirher eai  ahll t wolly aeai tn tes  \n",
      "\"hesday 18. Iy mo otde  tpon the sauim af t l tour saal  and the  tete aotsvrth e crrtnt  oo tar  tou  mourh ah trccyezard toneng the soyeof tleeted  and the sittle pr  wrOUEAMENGEREUS 1\n",
      " aen the sizard tnake the sanee thet ful  and toa ty tte  te sraceourenty tvd rt ne trwkett tnd tzma seoli  tuy un y an the caeatuektntnber  ahe sisceneteon  tf tur shesght   afr h eb, aord  a hall bn thesgwalle bnd tftthes w fevd s ateice of to e opteen trrion \n",
      "\n",
      "\"Wt t wae  aa se euid th tod an taery mhengs Mut In the snening  a   tt ws anoe th te r tn  aoret tfe ooiel tonf   a n  sih theue thrl  aebl and tee ty troe trom the eyweow tiet ies savpyned tte wnaye  d toe cizard t cremlteble th tou  toul  The Lttend ng the sanknorh ah e d thth terl tnd tast ang toeught   I mhen er  sarder ul foeng  bwn tircnow  wel \"Tut te can  n tes elf tnlhgedher tioe y  aot iot ing tet tnsen ee  ahire ahe  sti tod tostir ur d  and the r srr  teaerkeble  and the snprciee  af tis sind tansirc  a hm auce  an au wer tnoe th taeeein then wo e tas at―lli_eb ond M M _Che wost otell bote ae tes\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "t was auite pelignad tonverneng tes  ar y aeairenga-es el  tecember 12, 1755._\n",
      "\n",
      "_Mery coar Srother_,hon on the eealow mea  Tut Ie hecaue ooiveus anainetred tpter tis faet orant ng tnd ttuaal ng  ahicehe sizard.eaeng trrteoo the strs and totlod tThe d th bestmt ent  but  glory be to tod, tt wauld nottatl bover be t oe tnd oore oh tem thes mpem tn ty tiellest urr the slidegroom  Tnoenn ay dear  Tyy  t wae tt \"Hnd th deow the sringstn thue,  ecause  tou  soul wo test tn tis. \n",
      "\"                  Youton ot besoicedin trrn   ahene sttp. _Paul_ meys,  ere  and teeo ht tn o t gaome  \n",
      "Fonday 26. I waa \n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "\n",
    "# Epoch [1/10], Loss: 1.3516\n",
    "# Epoch [2/10], Loss: 1.2397\n",
    "# Epoch [3/10], Loss: 1.2223\n",
    "# Epoch [4/10], Loss: 1.2145\n",
    "# Epoch [5/10], Loss: 1.2100\n",
    "# Epoch [6/10], Loss: 1.2070\n",
    "# Epoch [7/10], Loss: 1.2047\n",
    "# Epoch [8/10], Loss: 1.2028\n",
    "# Epoch [9/10], Loss: 1.2028\n",
    "# Epoch [10/10], Loss: 1.2003\n",
    "# 3,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "t  be ceatgnad  ahe snswered  “I wm sesignad  aut  ot o waght save besdid from the strmon  Tnls, Ihe  tn titling th bsder ake ahe sete w wm suite aesd orit  ah l  a                    ney theu arsiess an te hased. Tut Ilahough the sanch insohs aerd y dound mo move  aut ttill t had nhe buessengsof thtlenas soeetnah ty shste   Oot s whe thet to sond  aon bealntatnd sofel\" Hhe seeyed ooevent y tor th  totmcgious tore tor te boildren  T ffly iasd d t rht of  cer  of ter srms tnd seny tf icial  af theuctearrce. Bet I wauld not bet toal airryness oore soudt eoed to boviroy aJe_, aor tt I do 't kit i\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "\n",
    "# Epoch [1/10], Loss: 1.3373\n",
    "# Epoch [2/10], Loss: 1.2145\n",
    "# Epoch [3/10], Loss: 1.1963\n",
    "# Epoch [4/10], Loss: 1.1881\n",
    "# Epoch [5/10], Loss: 1.1832\n",
    "# Epoch [6/10], Loss: 1.1799\n",
    "# Epoch [7/10], Loss: 1.1775\n",
    "# Epoch [8/10], Loss: 1.1758\n",
    "# Epoch [9/10], Loss: 1.1740\n",
    "# Epoch [10/10], Loss: 1.1724\n",
    "# 4,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "et t antented  But Iover sogd  I  is ot iaery ody ne tp thesg onoue wn ty sivg ng terrt, and tove tnn thy saranched out tnsopd oo tim,tnd teb wat iue nd  aIe  shall be sept in t l tis soys, and teess  o \"Ihet aaart aal bath tandiaoch aove, What aa rtd the soyer  aha Lest on trrptng  And thrk if thes th se ieve ie widd ior ty  \n",
      "Sunday 21. Ihis dorninde an orely so tod, ahth ut sicfer ng aou  smagin  B  iheme toringe  that Iou ahould bhenk iou aivetnain t tou trd tore  anless tou aorl inain an o th d tir ao sorte, aoe sndised te tot th tea te seahe   ao tes the sanfng af the sor of hyn,. Ie whok\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "\n",
    "# Epoch [1/10], Loss: 1.2567\n",
    "# Epoch [2/10], Loss: 1.1392\n",
    "# Epoch [3/10], Loss: 1.1319\n",
    "# Epoch [4/10], Loss: 1.1351\n",
    "# Epoch [5/10], Loss: 1.1410\n",
    "# Epoch [6/10], Loss: 1.1484\n",
    "# Epoch [7/10], Loss: 1.1555\n",
    "# Epoch [8/10], Loss: 1.1632\n",
    "# Epoch [9/10], Loss: 1.1708\n",
    "# Epoch [10/10], Loss: 1.1794\n",
    "# 4,192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "ud tirrt ond toaded ter tead tfer the stge of the u   Tnterwtoky snventures a heached tzat r\"wney thhtholl sonsinued Oord, wet mot oy srrdish terrt iee  eonsoare txpeeding toearl aet hew sor ais ae houedoft  “N hhat a seeet soviour teaws \"Oo had sor  r y toxl d tp tot  aut the sitten arve m sotfeohe vg to braschitir tdeal_ pewtrines  and teve tpoth  brrticularly theue wf teath  ar ahe saart ess ofe lf tn tir  an t sorner ohe sorld onowesh tot tn    th srrple oh such oore tnvance  in toece toat t t hane sanried  Ihe was ahuly ssdhoaplesi trr thme tn e tree yng  Oh hade tovd to bive the soneom o\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)\n",
    "\n",
    "# Epoch [1/10], Loss: 1.2739\n",
    "# Epoch [2/10], Loss: 1.1504\n",
    "# Epoch [3/10], Loss: 1.1516\n",
    "# Epoch [4/10], Loss: 1.1677\n",
    "# Epoch [5/10], Loss: 1.1936\n",
    "# Epoch [6/10], Loss: 1.2190\n",
    "# Epoch [7/10], Loss: 1.2252\n",
    "# Epoch [8/10], Loss: 1.2317\n",
    "# Epoch [9/10], Loss: 1.2414\n",
    "# Epoch [10/10], Loss: 1.2528\n",
    "# 5 rnn ,192 hidden state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
