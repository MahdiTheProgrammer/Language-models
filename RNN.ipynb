{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¹', '‒', '—', '―', '‘', '’', '“', '”', '•', '™', '♠', '♦', '\\ufeff']\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '?', 28: 'A', 29: 'B', 30: 'C', 31: 'D', 32: 'E', 33: 'F', 34: 'G', 35: 'H', 36: 'I', 37: 'J', 38: 'K', 39: 'L', 40: 'M', 41: 'N', 42: 'O', 43: 'P', 44: 'Q', 45: 'R', 46: 'S', 47: 'T', 48: 'U', 49: 'V', 50: 'W', 51: 'X', 52: 'Y', 53: 'Z', 54: '[', 55: ']', 56: '_', 57: 'a', 58: 'b', 59: 'c', 60: 'd', 61: 'e', 62: 'f', 63: 'g', 64: 'h', 65: 'i', 66: 'j', 67: 'k', 68: 'l', 69: 'm', 70: 'n', 71: 'o', 72: 'p', 73: 'q', 74: 'r', 75: 's', 76: 't', 77: 'u', 78: 'v', 79: 'w', 80: 'x', 81: 'y', 82: 'z', 83: '¹', 84: '‒', 85: '—', 86: '―', 87: '‘', 88: '’', 89: '“', 90: '”', 91: '•', 92: '™', 93: '♠', 94: '♦', 95: '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [char_to_idx[char] for char in text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(data) == len(text):\n",
    "#     print(f\"True! Length is {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = []\n",
    "# targets = []\n",
    "# seq_length = 100\n",
    "\n",
    "# for i in range(0, len(data) -seq_length):\n",
    "#     inputs.append(data[i:i+seq_length])\n",
    "#     targets.append(data[i+1:i+seq_length+1])\n",
    "\n",
    "# inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "# targets = torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputs.size())\n",
    "# print(targets.size())\n",
    "# inputs.to(device)\n",
    "# targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, seq_length):\n",
    "        chars = sorted(list(set(text)))\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "        self.vocab_size = len(chars)\n",
    "        self.seq_length = seq_length\n",
    "        self.data = [self.char_to_idx[char] for char in text]\n",
    "\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        for i in range(0, len(self.data) - seq_length):\n",
    "            self.inputs.append(self.data[i:i + seq_length])\n",
    "            self.targets.append(self.data[i + 1:i + seq_length + 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "\n",
    "# Load the text data\n",
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "seq_length = 50\n",
    "dataset = TextDataset(text, seq_length)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n",
    "\n",
    "# Model parameters\n",
    "input_size = dataset.vocab_size\n",
    "hidden_size = 128\n",
    "output_size = dataset.vocab_size\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (embedding): Embedding(96, 128)\n",
       "  (rnn): RNN(128, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=96, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5196\n",
      "Epoch [2/10], Loss: 1.4275\n",
      "Epoch [3/10], Loss: 1.4144\n",
      "Epoch [4/10], Loss: 1.4083\n",
      "Epoch [5/10], Loss: 1.4043\n",
      "Epoch [6/10], Loss: 1.4016\n",
      "Epoch [7/10], Loss: 1.3999\n",
      "Epoch [8/10], Loss: 1.3980\n",
      "Epoch [9/10], Loss: 1.3972\n",
      "Epoch [10/10], Loss: 1.3962\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Initialize hidden state for the current batch\n",
    "        hidden = model.init_hidden(x_batch.size(0)).to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, hidden = model(x_batch, hidden)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, output_size), y_batch.view(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-6.723585605621338,\n",
       " -3.8264291286468506,\n",
       " -3.2240824699401855,\n",
       " -16.451496124267578,\n",
       " -23.411029815673828,\n",
       " -29.336402893066406,\n",
       " -22.524686813354492,\n",
       " -6.478598594665527,\n",
       " -13.270509719848633,\n",
       " -11.285575866699219,\n",
       " -12.38095474243164,\n",
       " -1.6375879049301147,\n",
       " -1.388867974281311,\n",
       " 0.30989038944244385,\n",
       " -12.410364151000977,\n",
       " -14.931523323059082,\n",
       " -12.222330093383789,\n",
       " -13.27371597290039,\n",
       " -15.596689224243164,\n",
       " -11.92841911315918,\n",
       " -14.370338439941406,\n",
       " -14.55559253692627,\n",
       " -19.44388198852539,\n",
       " -15.277057647705078,\n",
       " -12.98617172241211,\n",
       " -6.768560409545898,\n",
       " -4.385221481323242,\n",
       " -3.9468653202056885,\n",
       " -10.544624328613281,\n",
       " -4.4307379722595215,\n",
       " -7.464421272277832,\n",
       " -5.638528347015381,\n",
       " -9.103068351745605,\n",
       " -14.175461769104004,\n",
       " -6.72966194152832,\n",
       " -10.394250869750977,\n",
       " -5.823312282562256,\n",
       " -9.328401565551758,\n",
       " -11.48056411743164,\n",
       " -9.701556205749512,\n",
       " -11.409364700317383,\n",
       " -3.88547682762146,\n",
       " -3.6877083778381348,\n",
       " -13.180563926696777,\n",
       " -19.027984619140625,\n",
       " -11.714963912963867,\n",
       " -7.95164680480957,\n",
       " -3.2856781482696533,\n",
       " -4.3572540283203125,\n",
       " -15.37040901184082,\n",
       " -16.26197052001953,\n",
       " -33.30805969238281,\n",
       " -16.466800689697266,\n",
       " -3.738860607147217,\n",
       " -19.496856689453125,\n",
       " -19.435218811035156,\n",
       " -0.34627094864845276,\n",
       " 5.519898414611816,\n",
       " 1.3202084302902222,\n",
       " 4.783045291900635,\n",
       " 5.3076491355896,\n",
       " 6.224412441253662,\n",
       " 8.75678539276123,\n",
       " 2.094480037689209,\n",
       " 0.7042858600616455,\n",
       " 6.0711798667907715,\n",
       " -3.304755210876465,\n",
       " 0.9971860647201538,\n",
       " 5.902186870574951,\n",
       " 8.796693801879883,\n",
       " 11.651796340942383,\n",
       " 3.9405946731567383,\n",
       " 5.627159595489502,\n",
       " 0.6953699588775635,\n",
       " 5.414634704589844,\n",
       " 10.502532005310059,\n",
       " 10.93440055847168,\n",
       " 2.873472213745117,\n",
       " 2.6648905277252197,\n",
       " -1.96797776222229,\n",
       " 4.815915584564209,\n",
       " -1.1489837169647217,\n",
       " 1.5830702781677246,\n",
       " -20.735227584838867,\n",
       " -21.43642807006836,\n",
       " -12.820457458496094,\n",
       " -10.917695999145508,\n",
       " -19.0369930267334,\n",
       " -7.699943542480469,\n",
       " -10.889383316040039,\n",
       " -18.281490325927734,\n",
       " -18.828271865844727,\n",
       " -20.20768165588379,\n",
       " -16.278947830200195,\n",
       " -14.95144271850586,\n",
       " -28.403209686279297]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1,1].size()\n",
    "output[1,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 50, 96])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "\n",
      "Predicted Text from the last batch of the last epoch:\n",
      "eleur opder tnt stncg , &n thet tn the storp  tltotn i she  th traase tnd tfher  Bord, sor iventy  b tn tim weaeete and then the sresty sroncess ouynee t tn travate pety  and ta sind ias tn to e teasutvery thiught  ahudstnd tard  ahldeth thes droryou tarths  an was tte  etea  ahet Ihe sar   of ton t tn ws tne  to te tefore the r lontersions ahth tehmg tolnvns e  and the sitten tenned th tyny piret consinuedth teclntett  ahll tnr sves ine soll  tf  \n",
      "\"Iow ds tncle Hewry   ahe sxduired  anter t srr esh-andtvee oonst snr ng tnd the  tycmieeng tn  O tes  ahin te sholl b peareon t l the salless of t\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = output.argmax(dim=-1)\n",
    "\n",
    "predicted_indices = predicted_indices.view(-1).tolist()\n",
    "\n",
    "print(len(predicted_indices))\n",
    "\n",
    "predicted_chars = [dataset.idx_to_char[idx] for idx in predicted_indices]\n",
    "\n",
    "predicted_text = ''.join(predicted_chars)\n",
    "\n",
    "print(\"\\nPredicted Text from the last batch of the last epoch:\")\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
