{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification\n",
    "#### In this project I am going to classify reviews in to positive and negetive reviews. I am going to use Embedding, LSTM and a fully connected layer at the end. For sake of learning I am not going to use any pretrained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I am running on RTX 4070 gpu. At first I check how many unique words are in my dataset so I choose between word level and char level. I could use pretrained ones but I want to do it all by myself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\panah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\panah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Datasets/dataset.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 133264\n"
     ]
    }
   ],
   "source": [
    "all_reviews = ' '.join(df['review'].astype(str).tolist())\n",
    "\n",
    "tokens = word_tokenize(all_reviews.lower()) \n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "tokens = [word.translate(translator) for word in tokens]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "unique_words = set(filtered_words)\n",
    "\n",
    "num_unique_words = len(unique_words)\n",
    "\n",
    "print(f\"Number of unique words: {num_unique_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, file_path, vocab_size=133000, max_length=100):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = word_tokenize\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.translator = str.maketrans('', '', string.punctuation)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # Prepare the tokenizer and word index\n",
    "        all_reviews = ' '.join(self.df['review'].astype(str).tolist()).lower()\n",
    "        tokens = word_tokenize(all_reviews)\n",
    "        tokens = [word.translate(self.translator) for word in tokens]\n",
    "        tokens = [word for word in tokens if word.isalpha() and word not in self.stop_words]\n",
    "        \n",
    "        # Create word index\n",
    "        unique_words = set(tokens)\n",
    "        self.word_to_idx = {word: idx+1 for idx, word in enumerate(unique_words)}  # +1 to reserve 0 for padding\n",
    "        self.word_to_idx['<PAD>'] = 0  # Add padding token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = self.df.loc[idx, 'review']\n",
    "        label = self.df.loc[idx, 'sentiment']\n",
    "        tokens = self.tokenizer(review.lower())\n",
    "        tokens = [word.translate(self.translator) for word in tokens]\n",
    "        tokens = [word for word in tokens if word.isalpha() and word not in self.stop_words]\n",
    "        \n",
    "        # Pad or truncate tokens to max_length\n",
    "        if len(tokens) < self.max_length:\n",
    "            tokens.extend(['<PAD>'] * (self.max_length - len(tokens)))\n",
    "        else:\n",
    "            tokens = tokens[:self.max_length]\n",
    "        \n",
    "        text_indices = [self.word_to_idx.get(word, 0) for word in tokens]\n",
    "        \n",
    "        return {\n",
    "            'text': torch.tensor(text_indices, dtype=torch.long),\n",
    "            'label': torch.tensor(1 if label == 'positive' else 0, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(file_path=file_path)\n",
    "\n",
    "# Define batch size and create DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)  # +1 to account for padding token\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = hidden[-1]  # Select the hidden state from the last LSTM layer\n",
    "        output = torch.sigmoid(self.fc(hidden))\n",
    "        return output\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model parameters\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "output_dim = 1  # Binary classification\n",
    "\n",
    "model = SimpleModel(num_unique_words, embedding_dim, hidden_dim, output_dim)\n",
    "model = model.to(device)  # Send model to GPU\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1302/1563, Evaluation Loss: 0.7163463253032119\n",
      "Epoch 1/10, Average Train Loss: 0.7855103508325724\n",
      "Epoch 2/10, Batch 1302/1563, Evaluation Loss: 0.5600296687263953\n",
      "Epoch 2/10, Average Train Loss: 0.6138906921560948\n",
      "Epoch 3/10, Batch 1302/1563, Evaluation Loss: 0.3275364033396253\n",
      "Epoch 3/10, Average Train Loss: 0.425521829065222\n",
      "Epoch 4/10, Batch 1302/1563, Evaluation Loss: 0.2299263049129524\n",
      "Epoch 4/10, Average Train Loss: 0.3018931974184055\n",
      "Epoch 5/10, Batch 1302/1563, Evaluation Loss: 0.1786921857201101\n",
      "Epoch 5/10, Average Train Loss: 0.2212680392554746\n",
      "Epoch 6/10, Batch 1302/1563, Evaluation Loss: 0.12337760397803194\n",
      "Epoch 6/10, Average Train Loss: 0.16283794107202154\n",
      "Epoch 7/10, Batch 1302/1563, Evaluation Loss: 0.10005254101914711\n",
      "Epoch 7/10, Average Train Loss: 0.11825593493771382\n",
      "Epoch 8/10, Batch 1302/1563, Evaluation Loss: 0.06522865805371236\n",
      "Epoch 8/10, Average Train Loss: 0.08612569265533239\n",
      "Epoch 9/10, Batch 1302/1563, Evaluation Loss: 0.04645322074940138\n",
      "Epoch 9/10, Average Train Loss: 0.06157360228468091\n",
      "Epoch 10/10, Batch 1302/1563, Evaluation Loss: 0.05726512843395934\n",
      "Epoch 10/10, Average Train Loss: 0.048288356634752394\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "evaluate_every = 20  # Evaluate the model every 20 batches\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    model.train()  # Set model to training mode\n",
    "    eval = False\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        if batch_idx  > 1300 and eval == False:\n",
    "            model.eval()  # Set model to evaluation mode         \n",
    "            total_eval_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for eval_idx ,eval_batch in enumerate(dataloader):  # Use the same dataloader for evaluation\n",
    "                    if eval_idx > 1300:\n",
    "                        eval_texts = eval_batch['text'].to(device)\n",
    "                        eval_labels = eval_batch['label'].to(device)\n",
    "                        eval_outputs = model(eval_texts).squeeze()\n",
    "                        eval_loss = criterion(eval_outputs, eval_labels)\n",
    "                        total_eval_loss += eval_loss.item()\n",
    "            \n",
    "            avg_eval_loss = total_eval_loss / (len(dataloader) - 1300)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(dataloader)}, Evaluation Loss: {avg_eval_loss}\")\n",
    "            \n",
    "            model.train()  # Set model back to training mode after evaluation\n",
    "            eval = True\n",
    "        else:\n",
    "            texts = batch['text'].to(device)  # Send data to GPU\n",
    "            labels = batch['label'].to(device)  # Send labels to GPU\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Evaluate the model every 'evaluate_every' batches\n",
    "\n",
    "    \n",
    "    avg_loss = total_loss / (len(dataloader) - 263)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Train Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'text_model_last_version.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is: This product is amazing! : positive\n",
      "The sentence is: not interesting : negative\n",
      "The sentence is: I Enjoyed iT : positive\n",
      "The sentence is: It was suprisingly Boring : negative\n",
      "The sentence is: not good : negative\n",
      "The sentence is: I can say i want to watch it again : positive\n",
      "The sentence is: incredible : positive\n",
      "The sentence is: hate : negative\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input(sentence, word_to_idx, max_length=100):\n",
    "    # Tokenize, remove punctuation and stop words, and pad/truncate the sentence\n",
    "    tokenizer = word_tokenize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    tokens = tokenizer(sentence.lower())\n",
    "    tokens = [word.translate(translator) for word in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    \n",
    "    # Pad or truncate tokens to max_length\n",
    "    if len(tokens) < max_length:\n",
    "        tokens.extend(['<PAD>'] * (max_length - len(tokens)))\n",
    "    else:\n",
    "        tokens = tokens[:max_length]\n",
    "    \n",
    "    text_indices = [word_to_idx.get(word, 0) for word in tokens]\n",
    "    \n",
    "    return torch.tensor(text_indices, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def predict_sentiment(model, sentence, word_to_idx, device, max_length=100):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    preprocessed_sentence = preprocess_input(sentence, word_to_idx, max_length).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(preprocessed_sentence).squeeze()\n",
    "        prediction = torch.round(output).item()\n",
    "        \n",
    "    return \"positive\" if prediction == 1 else \"negative\"\n",
    "\n",
    "# Example usage\n",
    "# Load the trained model\n",
    "model = SimpleModel(len(dataset.word_to_idx), embedding_dim, hidden_dim, output_dim)\n",
    "model.load_state_dict(torch.load('text_model.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# Make a prediction\n",
    "sentences = [\"This product is amazing!\", \"not interesting\", \"I Enjoyed iT\", \"It was suprisingly Boring\",\"not good\", \"I can say i want to watch it again\", 'incredible', 'hate']\n",
    "for sentence in sentences:\n",
    "    prediction = predict_sentiment(model, sentence, dataset.word_to_idx, device)\n",
    "    print(f\"The sentence is: {sentence} : {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status: Done! the model is perfoming pretty well in prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
